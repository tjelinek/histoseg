{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jelinek/recetox/src/notebooks/FullResolution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/jelinek/recetox/')\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from ml.eval import eval_model\n",
    "from ml.pipeline import FeitDataPipeline\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from cfg import *\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "\n",
    "name = \"MySimpleCNN-v2-reduced-atrous-convolution\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from ml.losses import my_sparse_categorical_loss\n",
    "from ml.util import FeitClasMapGen\n",
    "from keras import activations\n",
    "\n",
    "\n",
    "class MyAtrousCNN(FeitDataPipeline):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = self.get_compiled_model()\n",
    "        self.params.name = name\n",
    "        self.params.epochs = 200\n",
    "        self.batch_size = 16\n",
    "        self.params.tile_size=256\n",
    "        self.params.number_of_classes = 11\n",
    "\n",
    "        self.data_loader_training = self.get_data_loader_training()\n",
    "        self.data_loader_validation = self.get_data_loader_validation()\n",
    "\n",
    "    @staticmethod\n",
    "    def convolution_block(block_input, num_filters=256, kernel_size=3, dilation_rate=1, padding=\"same\", use_bias=False):\n",
    "        x = keras.layers.Conv2D(num_filters, kernel_size=kernel_size, dilation_rate=dilation_rate, padding=\"same\",\n",
    "            use_bias=use_bias, kernel_initializer=keras.initializers.HeNormal())(block_input)\n",
    "        \"\"\"\n",
    "        Function source: https://keras.io/examples/vision/deeplabv3_plus/\n",
    "        \"\"\"\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(activations.relu)(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def DilatedSpatialPyramidPooling(dspp_input):\n",
    "        \"\"\"\n",
    "        Function source: https://keras.io/examples/vision/deeplabv3_plus/\n",
    "        \"\"\"\n",
    "\n",
    "        dims = dspp_input.shape\n",
    "        x = keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "        x = MyAtrousCNN.convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = keras.layers.UpSampling2D(\n",
    "            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",)(x)\n",
    "\n",
    "        out_1 = MyAtrousCNN.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "        out_6 = MyAtrousCNN.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "        out_12 = MyAtrousCNN.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "        out_18 = MyAtrousCNN.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "        x = keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = MyAtrousCNN.convolution_block(x, kernel_size=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_compiled_model():\n",
    "        inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), padding='same')(inputs)\n",
    "\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), padding='same', name=\"conv128\")(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=64, kernel_size=5, strides=(1, 1), padding='same', name=\"conv64\")(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=128, kernel_size=5, strides=(1, 1), padding='same', name=\"conv32\")(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=256, kernel_size=5, strides=(1, 1), padding='same', name=\"conv16\")(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=512, kernel_size=5, strides=(1, 1), dilation_rate=2, padding='same', name=\"conv8\")(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        outputs = keras.layers.Dense(units=11, activation='softmax')(x)\n",
    "\n",
    "        base_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        ## Code below adapted from https://keras.io/examples/vision/deeplabv3_plus/\n",
    "        x = base_model.get_layer(\"conv8\").output\n",
    "        x = MyAtrousCNN.DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "        input_a = keras.layers.UpSampling2D(\n",
    "            size=(256 // 16 // x.shape[1], 256 // 16 // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        input_b = base_model.get_layer(\"conv16\").output\n",
    "        input_b = MyAtrousCNN.convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "        x = keras.layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "        x = MyAtrousCNN.convolution_block(x)\n",
    "        x = MyAtrousCNN.convolution_block(x)\n",
    "        x = keras.layers.MaxPooling2D()(x)\n",
    "        #x = keras.layers.Down(\n",
    "        #    size=(256 // x.shape[1], 256 // x.shape[2]),\n",
    "        #    interpolation=\"bilinear\",\n",
    "        # )(x)\n",
    "        model_output = keras.layers.Conv2D(11, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "\n",
    "        final_model = keras.Model(inputs=inputs, outputs=model_output)\n",
    "        final_model.summary()\n",
    "\n",
    "        return final_model\n",
    "\n",
    "    def execute_pipeline(self, perform_validation=True, save_model=True, perform_test_segmentation=True):\n",
    "        data_train = self.data_loader_training\n",
    "        data_valid = self.data_loader_validation\n",
    "\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy',\n",
    "                           optimizer=self.get_optimizer(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        self._train_model(data_train, data_valid)\n",
    "\n",
    "    def get_data_loader_training(self):\n",
    "        datagen_train = FeitClasMapGen(horizontal_flip=True, vertical_flip=True, samplewise_center=True,\n",
    "                                           samplewise_std_normalization=True)\n",
    "\n",
    "        return datagen_train.flow_from_directory(directory=self.params.data_training, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size, self.params.tile_size))\n",
    "\n",
    "    def get_data_loader_validation(self):\n",
    "        datagen_valid = FeitClasMapGen(samplewise_center=True, samplewise_std_normalization=True)\n",
    "        return datagen_valid.flow_from_directory(directory=self.params.data_validation, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size, self.params.tile_size))\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "\n",
    "    def _train_model(self, data_train, data_valid):\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                      patience=30, min_lr=1e-4, verbose=1,\n",
    "                                      cooldown=20)\n",
    "\n",
    "        class_weights = {k : 1.0 for k in range(self.params.number_of_classes)}\n",
    "        class_weights[self.params.number_of_classes] = 0.0\n",
    "\n",
    "        self.model.fit(data_train,\n",
    "                       steps_per_epoch=250,\n",
    "                       epochs=20,\n",
    "                       shuffle=True,\n",
    "                       validation_data=data_valid,\n",
    "                       validation_freq=100,\n",
    "                       verbose=1,\n",
    "                       validation_steps=10000,\n",
    "                       callbacks=[self.tensorboard, reduce_lr, PlotLossesKerasTF()])\n",
    "\n",
    "        print('Ahoj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 256, 256, 16  1216        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 128, 128, 16  0          ['conv2d_11[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 128, 16  64         ['max_pooling2d_7[0][0]']        \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv128 (Conv2D)               (None, 128, 128, 32  12832       ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 32)  0           ['conv128[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 64, 32)  128         ['max_pooling2d_8[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv64 (Conv2D)                (None, 64, 64, 64)   51264       ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 64)  0           ['conv64[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 32, 64)  256         ['max_pooling2d_9[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv32 (Conv2D)                (None, 32, 32, 128)  204928      ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 16, 16, 128)  0          ['conv32[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 128)  512        ['max_pooling2d_10[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv16 (Conv2D)                (None, 16, 16, 256)  819456      ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 8, 8, 256)   0           ['conv16[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 256)   1024        ['max_pooling2d_11[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv8 (Conv2D)                 (None, 8, 8, 512)    3277312     ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 512)   0           ['conv8[0][0]']                  \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 1, 1, 256)    131328      ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 256)    131072      ['conv8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 256)    1179648     ['conv8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 256)    1179648     ['conv8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 256)    1179648     ['conv8[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 1, 1, 256)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)   0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 1280)   0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]',          \n",
      "                                                                  'activation_12[0][0]',          \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 256)    327680      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 48)   12288       ['conv16[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 48)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 256)  0          ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 304)  0           ['up_sampling2d_3[0][0]',        \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 256)  700416      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 256)  589824      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 8, 8, 256)   0           ['activation_17[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 11)     2827        ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,811,755\n",
      "Trainable params: 9,806,571\n",
      "Non-trainable params: 5,184\n",
      "__________________________________________________________________________________________________\n",
      "Initializing training datagen\n",
      "\n",
      "Processing file 1\n",
      "Processing grid point 663499 out of 663499\r\n",
      "Processing file 2\n",
      "Processing grid point 1599360 out of 1599360\r\n",
      "Processing file 3\n",
      "Processing grid point 1541550 out of 1541550\r\n",
      "Processing file 4\n",
      "Initializing training datagen out of 3518304\n",
      "\n",
      "Processing file 1\n",
      "Processing grid point 663499 out of 663499\r\n",
      "Processing file 2\n",
      "Processing grid point 1599360 out of 1599360\r\n",
      "Processing file 3\n",
      "Processing grid point 1541550 out of 1541550\r\n",
      "Processing file 4\n",
      "Processing grid point 3518304 out of 3518304\r"
     ]
    }
   ],
   "source": [
    "pipeline = MyAtrousCNN(train_data_dir='data/Feit_colon-annotation_valid/',\n",
    "                        valid_data_dir='data/Feit_colon-annotation_valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "142/250 [================>.............] - ETA: 9s - loss: nan - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_775735/39318638.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mperform_validation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperform_test_segmentation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_775735/169460133.py\u001B[0m in \u001B[0;36mexecute_pipeline\u001B[0;34m(self, perform_validation, save_model, perform_test_segmentation)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 123\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_data_loader_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_775735/169460133.py\u001B[0m in \u001B[0;36m_train_model\u001B[0;34m(self, data_train, data_valid)\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0mclass_weights\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber_of_classes\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m         self.model.fit(data_train,\n\u001B[0m\u001B[1;32m    155\u001B[0m                        \u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m250\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m                        \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1206\u001B[0m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1207\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1208\u001B[0;31m           \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1209\u001B[0m             with tf.profiler.experimental.Trace(\n\u001B[1;32m   1210\u001B[0m                 \u001B[0;34m'train'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36msteps\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1248\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Set by `catch_stop_iteration`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1249\u001B[0m         \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1250\u001B[0;31m       \u001B[0moriginal_spe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_steps_per_execution\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1251\u001B[0m       can_run_full_execution = (\n\u001B[1;32m   1252\u001B[0m           \u001B[0moriginal_spe\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    643\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    644\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 645\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    646\u001B[0m     raise NotImplementedError(\n\u001B[1;32m    647\u001B[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36mread_value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    718\u001B[0m     \"\"\"\n\u001B[1;32m    719\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Read\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 720\u001B[0;31m       \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_variable_op\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    721\u001B[0m     \u001B[0;31m# Return an identity so it can get placed on whatever device the context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    722\u001B[0m     \u001B[0;31m# specifies instead of the device where the variable is.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36m_read_variable_op\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    697\u001B[0m           \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_and_set_handle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 699\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_and_set_handle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    700\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36mread_and_set_handle\u001B[0;34m()\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread_and_set_handle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 689\u001B[0;31m       result = gen_resource_variable_ops.read_variable_op(\n\u001B[0m\u001B[1;32m    690\u001B[0m           self.handle, self._dtype)\n\u001B[1;32m    691\u001B[0m       \u001B[0m_maybe_set_handle_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001B[0m in \u001B[0;36mread_variable_op\u001B[0;34m(resource, dtype, name)\u001B[0m\n\u001B[1;32m    468\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    469\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 470\u001B[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[1;32m    471\u001B[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001B[1;32m    472\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pipeline.execute_pipeline(perform_validation=True, perform_test_segmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_775735/2552927956.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_775735/2552927956.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.7172.26/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m                 \u001B[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    746\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpydev_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSTATE_SUSPEND\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 747\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    748\u001B[0m                     \u001B[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    749\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrace_dispatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.7172.26/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0;31m# IFDEF CYTHON\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.7172.26/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.7172.26/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pipeline.save_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training datagen\n",
      "\n",
      "Processing file 1\n",
      "Processing grid point 663499 out of 663499\r\n",
      "Processing file 2\n",
      "Processing grid point 1599360 out of 1599360\r\n",
      "Processing file 3\n",
      "Processing grid point 1541550 out of 1541550\r\n",
      "Processing file 4\n",
      "Processing grid point 3518304 out of 3518304\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FeitClasMapSequence' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_737291/1840242064.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m eval_model(pipeline.model,\n\u001B[0m\u001B[1;32m      2\u001B[0m            \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_data_loader_validation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m            \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m            \u001B[0mprint_confusion_matrix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m            save_misclassified=True)\n",
      "\u001B[0;32m~/recetox/src/ml/eval.py\u001B[0m in \u001B[0;36meval_model\u001B[0;34m(model, data_valid, pipeline_name, print_confusion_matrix, save_misclassified, min_confidence, measure_time)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0my_pred_max_high_confidence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred_max\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlow_confidence_indices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m     \u001B[0my_high_confidence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_valid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclasses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlow_confidence_indices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0mclass_labels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata_valid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclass_indices\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'FeitClasMapSequence' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "eval_model(pipeline.model,\n",
    "           pipeline.get_data_loader_validation(),\n",
    "           name,\n",
    "           print_confusion_matrix=True,\n",
    "           save_misclassified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = FeitDataPipeline.load_pipeline(pipeline_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml.eval import evaluate_segmentation_on_feit_annotation\n",
    "\n",
    "evaluation_path = Path('data/Feit_colon-annotation_valid/')\n",
    "\n",
    "segmentation_dir = Path('segmentations') / pipeline.params.name\n",
    "\n",
    "evaluate_segmentation_on_feit_annotation(evaluation_path, pipeline.build_segmenter(),\n",
    "                                         32, pipeline.params.class_names,\n",
    "                                         save_segmentations=True, segmentations_dir=segmentation_dir,\n",
    "                                         neighbourhood_size=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}