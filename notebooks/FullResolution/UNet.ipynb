{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jelinek/recetox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/jelinek/recetox/')\n",
    "\n",
    "from ml.eval import eval_model\n",
    "from ml.pipeline import FeitDataPipeline\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from cfg import *\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "\n",
    "name = \"MySimpleCNN-v2-reduced-atrous-convolution\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml.losses import my_sparse_categorical_loss\n",
    "from ml.util import FeitClasMapGen\n",
    "from keras import activations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DeepLabV3(FeitDataPipeline):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = self.get_compiled_model()\n",
    "        self.params.name = name\n",
    "        self.params.epochs = 200\n",
    "        self.batch_size = 16\n",
    "        self.params.tile_size=256\n",
    "        self.params.number_of_classes = 12\n",
    "\n",
    "        self.data_loader_training = self.get_data_loader_training()\n",
    "        self.data_loader_validation = self.get_data_loader_validation()\n",
    "\n",
    "    @staticmethod\n",
    "    def convolution_block(block_input, num_filters=256, kernel_size=3, dilation_rate=1, padding=\"same\", use_bias=False):\n",
    "        x = keras.layers.Conv2D(num_filters, kernel_size=kernel_size, dilation_rate=dilation_rate, padding=\"same\",\n",
    "            use_bias=use_bias, kernel_initializer=keras.initializers.HeNormal())(block_input)\n",
    "        \"\"\"\n",
    "        Function source: https://keras.io/examples/vision/deeplabv3_plus/\n",
    "        \"\"\"\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(activations.relu)(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def DilatedSpatialPyramidPooling(dspp_input):\n",
    "        \"\"\"\n",
    "        Function source: https://keras.io/examples/vision/deeplabv3_plus/\n",
    "        \"\"\"\n",
    "\n",
    "        dims = dspp_input.shape\n",
    "        x = keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "        x = DeepLabV3.convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = keras.layers.UpSampling2D(\n",
    "            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",)(x)\n",
    "\n",
    "        out_1 = DeepLabV3.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "        out_6 = DeepLabV3.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "        out_12 = DeepLabV3.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "        out_18 = DeepLabV3.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "        x = keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = DeepLabV3.convolution_block(x, kernel_size=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_compiled_model():\n",
    "        image_size = 256\n",
    "        inputs = keras.Input(shape=(256,256,3))\n",
    "\n",
    "        ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "        # Entry block\n",
    "        x = keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "        previous_block_activation = x  # Set aside residual\n",
    "\n",
    "        # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "        for filters in [64, 128, 256]:\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "            # Project residual\n",
    "            residual = keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "                previous_block_activation\n",
    "            )\n",
    "            x = keras.layers.add([x, residual])  # Add back residual\n",
    "            previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "        ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "        for filters in [256, 128, 64, 32]:\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = keras.layers.UpSampling2D(2)(x)\n",
    "\n",
    "            # Project residual\n",
    "            residual = keras.layers.UpSampling2D(2)(previous_block_activation)\n",
    "            residual = keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "            x = keras.layers.add([x, residual])  # Add back residual\n",
    "            previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "        # Add a per-pixel classification layer\n",
    "        outputs = keras.layers.Conv2D(11, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "    \n",
    "        # Define the model\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def execute_pipeline(self, perform_validation=True, save_model=True, perform_test_segmentation=True):\n",
    "        data_train = self.data_loader_training\n",
    "        data_valid = self.data_loader_validation\n",
    "\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy',\n",
    "                           optimizer=self.get_optimizer())\n",
    "\n",
    "\n",
    "        self._train_model(data_train, data_valid)\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1.)\n",
    "\n",
    "    def get_data_loader_training(self):\n",
    "        datagen_train = FeitClasMapGen(horizontal_flip=False, vertical_flip=False, samplewise_center=False,\n",
    "                                           samplewise_std_normalization=True)\n",
    "\n",
    "        return datagen_train.flow_from_directory(directory=self.params.data_training, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size, self.params.tile_size),\n",
    "                                                 broadcast=True)\n",
    "\n",
    "    def get_data_loader_validation(self):\n",
    "        datagen_valid = FeitClasMapGen(samplewise_center=False, samplewise_std_normalization=True)\n",
    "        return datagen_valid.flow_from_directory(directory=self.params.data_validation, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size, self.params.tile_size),\n",
    "                                                 broadcast=True)\n",
    "\n",
    "\n",
    "    def _train_model(self, data_train, data_valid):\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                      patience=30, min_lr=1e-4, verbose=1,\n",
    "                                      cooldown=20)\n",
    "\n",
    "        class_weights = {k : 1.0 for k in range(self.params.number_of_classes)}\n",
    "        class_weights[self.params.number_of_classes] = 0.0\n",
    "\n",
    "        self.model.fit(data_train,\n",
    "                       steps_per_epoch=250,\n",
    "                       epochs=20,\n",
    "                       shuffle=True,\n",
    "                       validation_data=data_valid,\n",
    "                       validation_freq=100,\n",
    "                       verbose=1,\n",
    "                       validation_steps=10000,\n",
    "                       callbacks=[self.tensorboard, reduce_lr, PlotLossesKerasTF()])\n",
    "\n",
    "        print(\"Ahoj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 32  896         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['conv2d_9[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 128, 128, 32  0           ['activation_15[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (SeparableC  (None, 128, 128, 64  2400       ['activation_16[0][0]']          \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 128, 128, 64  256        ['separable_conv2d_6[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (SeparableC  (None, 128, 128, 64  4736       ['activation_17[0][0]']          \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 128, 64  256        ['separable_conv2d_7[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 64)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 64)   2112        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 64, 64, 64)   0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 64, 64, 64)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_8 (SeparableC  (None, 64, 64, 128)  8896       ['activation_18[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 64, 64, 128)  512        ['separable_conv2d_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_9 (SeparableC  (None, 64, 64, 128)  17664      ['activation_19[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 64, 64, 128)  512        ['separable_conv2d_9[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 128)  8320        ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 32, 32, 128)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 32, 128)  0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_10 (Separable  (None, 32, 32, 256)  34176      ['activation_20[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32, 32, 256)  1024       ['separable_conv2d_10[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_11 (Separable  (None, 32, 32, 256)  68096      ['activation_21[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 32, 32, 256)  1024       ['separable_conv2d_11[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 256)  33024       ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 16, 16, 256)  0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 256)  0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 16, 16, 256)  590080     ['activation_22[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_transpose_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 16, 16, 256)  590080     ['activation_23[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_transpose_9[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 256)  0          ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 32, 32, 256)  0          ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 256)  65792       ['up_sampling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 32, 32, 256)  0           ['up_sampling2d_8[0][0]',        \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 32, 32, 256)  0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 32, 32, 128)  295040     ['activation_24[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_10[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 32, 32, 128)  147584     ['activation_25[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_11[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampling2D  (None, 64, 64, 256)  0          ['add_10[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampling2D  (None, 64, 64, 128)  0          ['batch_normalization_25[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 128)  32896       ['up_sampling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 64, 64, 128)  0           ['up_sampling2d_10[0][0]',       \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 64, 64, 128)  0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 64, 64, 64)  73792       ['activation_26[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_12[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2DTra  (None, 64, 64, 64)  36928       ['activation_27[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_13[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampling2D  (None, 128, 128, 12  0          ['add_11[0][0]']                 \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampling2D  (None, 128, 128, 64  0          ['batch_normalization_27[0][0]'] \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 64  8256        ['up_sampling2d_13[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 128, 128, 64  0           ['up_sampling2d_12[0][0]',       \n",
      "                                )                                 'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 128, 128, 64  0           ['add_12[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_14 (Conv2DTra  (None, 128, 128, 32  18464      ['activation_28[0][0]']          \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_14[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_28[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_15 (Conv2DTra  (None, 128, 128, 32  9248       ['activation_29[0][0]']          \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_15[0][0]']    \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 256, 256, 64  0          ['add_12[0][0]']                 \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampling2D  (None, 256, 256, 32  0          ['batch_normalization_29[0][0]'] \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 32  2080        ['up_sampling2d_15[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 256, 256, 32  0           ['up_sampling2d_14[0][0]',       \n",
      "                                )                                 'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 11  3179        ['add_13[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,061,291\n",
      "Trainable params: 2,057,515\n",
      "Non-trainable params: 3,776\n",
      "__________________________________________________________________________________________________\n",
      "Initializing training datagen\n",
      "\n",
      "Processing file 1\n",
      "Processing grid point 663499 out of 663499\r\n",
      "Processing file 2\n",
      "Processing grid point 1599360 out of 1599360\r\n",
      "Processing file 3\n",
      "Processing grid point 1541550 out of 1541550\r\n",
      "Processing file 4\n",
      "Initializing training datagen out of 3518304\n",
      "\n",
      "Processing file 1\n",
      "Processing grid point 663499 out of 663499\r\n",
      "Processing file 2\n",
      "Processing grid point 1599360 out of 1599360\r\n",
      "Processing file 3\n",
      "Processing grid point 1541550 out of 1541550\r\n",
      "Processing file 4\n",
      "Processing grid point 3518304 out of 3518304\r"
     ]
    }
   ],
   "source": [
    "pipeline = DeepLabV3(train_data_dir='data/Feit_colon-annotation_valid/',\n",
    "                        valid_data_dir='data/Feit_colon-annotation_valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAI4CAYAAACGFxPLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAp70lEQVR4nO3df5RlZ1kn+u9jJyFoEoH8ItBoB804BhCITW7uMBPjwIUk4xC8igZHEjHLLBzwylXQMKjDyKwlkjXicA0gg2iiMCTjoEQFESII3EsgnZgfJAi0kR+dRNJEDcRMlCTP/ePshqKt6qru81ZXVffns9ZZdc7e77v3s/c+Ve/5nr3PqeruAAAAMJ+vW+sCAAAADgTCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAA+6SqPl1VT1/rOmC9EK5gFRl0AAAOHsIVAABDVdUha10DrAXhCvazqnpIVf1qVd0+3X61qh4yzTumqv6wqv6uqv6mqj5YVV83zfvZqrqtqr5UVZ+oqqet7ZYAwExVvaKqfreqfqeqvpjkR9a6JlgL3lWA/e/lSU5L8qQkneQdSX4uyc8n+ekkO5IcO7U9LUlX1bcleVGSp3T37VW1Jcmm/Vs2AOzROUmek+S8JA9Z41pgTThzBfvfv0vyi919Z3fvTPKfkjxvmvflJCck+ebu/nJ3f7C7O8kDmQ1UJ1fVod396e7+yzWpHgAW9+Hu/v3ufrC7/9daFwNrQbiC/e9RST6z4PFnpmlJcnGS7Un+pKpuraqLkqS7tyd5cZJXJLmzqt5WVY8KAKwfn1vrAmCtCVew/92e5JsXPP6maVq6+0vd/dPd/dgk/zbJT+36bFV3v7W7/+XUt5P88v4tGwD2qNe6AFhrwhWsvkOr6vBdtyT/PcnPVdWxVXVMkl9I8jtJUlXfU1XfWlWV5IuZXQ74QFV9W1X96+mLL+5L8r+meQAArBPCFay+d2YWhnbdDk+yLcmNSW5Kcl2S/zy1PSnJe5Pck+TDSV7X3e/P7PNWr0ryhSR/neS4JP9hv20BAADLqtln5QEAAJiHM1cAAAADCFcAAAADCFcAAAADCFcAAAADHLLWBeyLY445prds2bLWZQCwF6699tovdPexa13HWjJ+AWw8ezN+bchwtWXLlmzbtm2tywBgL1TVZ9a6hrVm/ALYePZm/HJZIAAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwABDwlVVnVlVn6iq7VV10SLzq6peO82/sapO2W3+pqr686r6wxH1ALDxzTO2LNW3qh5RVe+pqk9NPx8+TT+6qt5XVfdU1a/ttp7vrKqbpmW9tqpqt/nfX1VdVVvH7wUANpK5w1VVbUpySZKzkpyc5LlVdfJuzc5KctJ0uzDJ63eb/5NJPj5vLQAcGOYZW5bpe1GSq7r7pCRXTY+T5L4kP5/kJYuU8/pp+bvWdeaCOo9M8n8l+cgcmwvAAWLEmatTk2zv7lu7+x+TvC3JObu1OSfJZT1zdZKHVdUJSVJVm5P8myRvGlALAAeGecaWPfU9J8ml0/1Lkzw7Sbr777v7Q5mFrK+YlndUd3+4uzvJZbv6TF6Z5NW79wPg4DQiXD06yecWPN4xTVtpm19N8jNJHhxQCwAHhnnGlj31Pb6770iS6edxK6hjx2LLqqonJ3lMd7ukHYAkY8JVLTKtV9Kmqr4nyZ3dfe2yK6m6sKq2VdW2nTt37kudAGwc+zy2rLDvXHVU1dcleU2Sn152AcYvgIPGiHC1I8ljFjzenOT2FbZ5apJnVdWnM7ts419X1e8stpLufmN3b+3urccee+yAsgFYx+YZW/bU9/MLLks/IcmdK6hj8yLLOjLJ45O8fxrDTkty5WJfamH8Ajh4jAhX1yQ5qapOrKrDkpyb5Mrd2lyZ5Lzpm51OS3J3d9/R3S/r7s3dvWXq96fd/cMDagJgY9vnsWWZvlcmOX+6f36Sd+ypiGl5X6qq06ZvCTwvyTu6++7uPqa7t0xj2NVJntXd2+bdcAA2rkPmXUB3319VL0ry7iSbkry5u2+uqhdM89+Q5J1Jzk6yPcm9SZ4/73oBOHDNM7Ys1Xda9KuSXFFVFyT5bJLn7FrndAbqqCSHVdWzkzyju29J8uNJfivJQ5O8a7oBwD9Rsy8/2li2bt3a27Z5cxBgI6mqa7v7oP5fUMYvgI1nb8avIf9EGAAA4GAnXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwgXAEAAAwwJFxV1ZlV9Ymq2l5VFy0yv6rqtdP8G6vqlGn6Y6rqfVX18aq6uap+ckQ9AGx8+zq27KlvVT2iqt5TVZ+afj58mn70NB7dU1W/ttt6vrOqbpqW9dqqqmn6T1XVLdO6r6qqb169vQHARjB3uKqqTUkuSXJWkpOTPLeqTt6t2VlJTppuFyZ5/TT9/iQ/3d3fnuS0JC9cpC8AB5l5xpZl+l6U5KruPinJVdPjJLkvyc8necki5bx+Wv6udZ05Tf/zJFu7+zuS/G6SV8+xyQAcAEacuTo1yfbuvrW7/zHJ25Kcs1ubc5Jc1jNXJ3lYVZ3Q3Xd093VJ0t1fSvLxJI8eUBMAG9s+jy3L9D0nyaXT/UuTPDtJuvvvu/tDmYWsr5iWd1R3f7i7O8llC/q8r7vvnZpenWTzmE0HYKMaEa4eneRzCx7vyD8NSMu2qaotSZ6c5COLraSqLqyqbVW1befOnfPWDMD6Ns/Ysqe+x3f3HUky/TxuBXXsWKaOJLkgybsWW4DxC+DgMSJc1SLTem/aVNURSf5nkhd39xcXW0l3v7G7t3b31mOPPXafiwVgQ5hnbFlJ32F1VNUPJ9ma5OLFFmD8Ajh4HDJgGTuSPGbB481Jbl9pm6o6NLNg9ZbufvuAegDY+OYZWw7bQ9/P77osfbrk784V1LHwcr+vqaOqnp7k5Um+q7v/YZllAXCAG3Hm6pokJ1XViVV1WJJzk1y5W5srk5w3fbPTaUnunga2SvIbST7e3b8yoBYADgz7PLYs0/fKJOdP989P8o49FTEt70tVddo0Zp23q09VPTnJryd5VncvF9IAOAjMfeaqu++vqhcleXeSTUne3N03V9ULpvlvSPLOJGcn2Z7k3iTPn7o/NcnzktxUVddP0/5Dd79z3roA2LjmGVuW6jst+lVJrqiqC5J8Nslzdq2zqj6d5Kgkh1XVs5M8o7tvSfLjSX4ryUMz+1zVrs9WXZzkiCT/Y/p29s9297OG7wwANoyaffnRxrJ169betm3bWpcBwF6oqmu7e+ta17GWjF8AG8/ejF9D/okwAADAwU64AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGEC4AgAAGOCQtS4A4GD05S9/OTt27Mh999231qUMd/jhh2fz5s059NBD17oUANaBjTLmjRi/hCuANbBjx44ceeSR2bJlS6pqrcsZprtz1113ZceOHTnxxBPXuhwA1oGNMOaNGr9cFgiwBu67774cffTR63aQ2VdVlaOPPnrdvzsJwP6zEca8UeOXcAWwRtbzIDOPA3W7ANh3G2FsGFGjcAUAADCAcAVwkDriiCPWugQA2C/215g3JFxV1ZlV9Ymq2l5VFy0yv6rqtdP8G6vqlJX2BeDgtBpjS1U9oqreU1Wfmn4+fJp+dFW9r6ruqapf220931lVN03Lem1N141U1UOq6vJp+keqasuq7QwAhnvggQeGL3PucFVVm5JckuSsJCcneW5Vnbxbs7OSnDTdLkzy+r3oC8Aq6u689KUvzeMf//g84QlPyOWXX54kueOOO3L66afnSU96Uh7/+Mfngx/8YB544IH8yI/8yFfavuY1r1mVmlZxbLkoyVXdfVKSq6bHSXJfkp9P8pJFynn9tPxd6zpzmn5Bkr/t7m9N8pokvzzHJgOwH7z//e/Pd3/3d+eHfuiH8oQnPGH48kd8FfupSbZ3961JUlVvS3JOklsWtDknyWXd3UmurqqHVdUJSbasoC/AAe0//cHNueX2Lw5d5smPOir/8d8+bkVt3/72t+f666/PDTfckC984Qt5ylOektNPPz1vfetb88xnPjMvf/nL88ADD+Tee+/N9ddfn9tuuy0f+9jHkiR/93d/N7TuBVZrbDknyRlT/0uTvD/Jz3b33yf5UFV968IipuUd1d0fnh5fluTZSd41LesVU9PfTfJrVVVTPatiNZ4rAKvthU9+aA7beU+S5JL3bc9f3nnP0OV/y3FH5IXf/a2LznvooZvyqIc99GumffSjH83HPvaxVfmXISMuC3x0ks8teLxjmraSNivpmySpqguraltVbdu5c+fcRQMw86EPfSjPfe5zs2nTphx//PH5ru/6rlxzzTV5ylOekt/8zd/MK17xitx000058sgj89jHPja33nprfuInfiJ//Md/nKOOOmq1ylqtseX47r4jSaafx62gjh1LLOsr6+nu+5PcneTo3Rdg/AJYX0499dRV+1+MI85cLfadhbu/a7dUm5X0nU3sfmOSNybJ1q1bV+1dQYD9baVnmFbLUidaTj/99HzgAx/IH/3RH+V5z3teXvrSl+a8887LDTfckHe/+9255JJLcsUVV+TNb37zapS1X8aWOetY0XpGjl9r/VwB2Bcf//jH8y3Hzr5Q4ld+4ElrW0ySb/iGb1i1ZY84c7UjyWMWPN6c5PYVtllJXwBW0emnn57LL788DzzwQHbu3JkPfOADOfXUU/OZz3wmxx13XH7sx34sF1xwQa677rp84QtfyIMPPpjv+77vyytf+cpcd911q1XWao0tn58u9dt1yd+dK6hj8xLL+sp6quqQJN+Y5G+WWR4AB7ARZ66uSXJSVZ2Y5LYk5yb5od3aXJnkRdN17/9bkru7+46q2rmCvgCsou/93u/Nhz/84TzxiU9MVeXVr351HvnIR+bSSy/NxRdfnEMPPTRHHHFELrvsstx22215/vOfnwcffDBJ8ku/9EurVdZqjS1XJjk/yaumn+/YUxHT8r5UVacl+UiS85L8P7st68NJvj/Jn67m560AWP/mDlfdfX9VvSjJu5NsSvLm7r65ql4wzX9DkncmOTvJ9iT3Jnn+nvrOWxMAy7vnntkHiqsqF198cS6++OKvmX/++efn/PPP/yf9VvFs1Ves4tjyqiRXVNUFST6b5Dm71llVn05yVJLDqurZSZ7R3bck+fEkv5XkoZl9kcW7pi6/keS3q2p7Zmeszh2/JwAYYdeYd8YZZ+SMM85YtfWMOHOV7n5nZoPcwmlvWHC/k7xwpX0BYDXGlu6+K8nTluizZYnp25I8fpHp92VBOAOAIf9EGAAA4GAnXAGskQP14zkH6nYBsO82wtgwokbhCmANHH744bnrrrs2xGCzN7o7d911Vw4//PC1LgWAdWIjjHmjxq8hn7kCYO9s3rw5O3bsyIH4T2UPP/zwbN68efmGABwUNsqYN2L8Eq4A1sChhx66av8dHgDWk4NpzHNZIAAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwABzhauqekRVvaeqPjX9fPgS7c6sqk9U1faqumjB9Iur6i+q6saq+r2qetg89QBw4Fhq7Fgwv6rqtdP8G6vqlOX67mncqqqXTe0/UVXPXDD9B6fl31xVr14w/Zuq6n1V9efT/LNXZ08AsFHMe+bqoiRXdfdJSa6aHn+NqtqU5JIkZyU5Oclzq+rkafZ7kjy+u78jySeTvGzOegA4ACwzduxyVpKTptuFSV6/gr6LjlvT/HOTPC7JmUleV1WbquroJBcneVp3Py7J8VX1tGlZP5fkiu5+8tT3dWP3AgAbzbzh6pwkl073L03y7EXanJpke3ff2t3/mORtU79095909/1Tu6uTbJ6zHgAODEuOHQuck+Synrk6ycOq6oRl+i41bp2T5G3d/Q/d/VdJtk/LeWyST3b3zqnde5N833S/kxw13f/GJLcP2G4ANrB5w9Xx3X1Hkkw/j1ukzaOTfG7B4x3TtN39aJJ3LbWiqrqwqrZV1badO3cu1QyAA8NKxo6l2uyp71Lj1lJ9tif551W1paoOySyMPWZq84okP1xVO5K8M8lPLLYhxi+Ag8ey4aqq3ltVH1vktvs7iEsuYpFpvds6Xp7k/iRvWWoh3f3G7t7a3VuPPfbYFa4agA1q2bFjD21W0ndF6+vuv03y40kuT/LBJJ/ObLxKkucm+a3u3pzk7CS/XVX/ZFw1fgEcPA5ZrkF3P32peVX1+ao6obvvmC7FuHORZjvy1Xf5ktmlf1+5dKKqzk/yPZldz77c4AfAwWGPY8cybQ7bQ9+lxq0l19fdf5DkD5LZWagkD0xtLsjs81np7g9X1eFJjsniYyEAB4F5Lwu8Msn50/3zk7xjkTbXJDmpqk6sqsMy+9Dvlcns25yS/GySZ3X3vXPWAsCBY8mxY4Erk5w3fWvgaUnuni7121PfpcatK5OcW1UPqaoTM/uSjI8mSVUdN/18eJJ/n+RNU5/PJnnaNO/bkxyexHV/AAexZc9cLeNVSa6oqgsyG2SekyRV9agkb+rus7v7/qp6UZJ3J9mU5M3dffPU/9eSPCTJe6oqSa7u7hfMWRMAG9xSY0dVvWCa/4bMPud0dmafi7o3yfP31Hda9KLj1rTsK5Lcktllfy/s7l1nqP5rVT1xuv+L3f3J6f5PJ/lvVfV/Z3bZ4Y+4AgPg4FYbcRzYunVrb9u2ba3LAGAvVNW13b11retYS8YvgI1nb8aveS8LBAAAIMIVAADAEMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAMIVAADAAHOFq6p6RFW9p6o+Nf18+BLtzqyqT1TV9qq6aJH5L6mqrqpj5qkHgAPHCsaOqqrXTvNvrKpTluu7p3Grql42tf9EVT1zwfQfnJZ/c1W9ercafqCqbpnmvXX8XgBgI5n3zNVFSa7q7pOSXDU9/hpVtSnJJUnOSnJykudW1ckL5j8myf+R5LNz1gLAAWK5sWNyVpKTptuFSV6/gr6LjlvT/HOTPC7JmUleV1WbquroJBcneVp3Py7J8VX1tKnPSUleluSp07wXj94PAGws84arc5JcOt2/NMmzF2lzapLt3X1rd/9jkrdN/XZ5TZKfSdJz1gLAgWO5sSPT48t65uokD6uqE5bpu9S4dU6St3X3P3T3XyXZPi3nsUk+2d07p3bvTfJ90/0fS3JJd/9tknT3nYO2HYANat5wdXx335Ek08/jFmnz6CSfW/B4xzQtVfWsJLd19w1z1gHAgWXJsWMFbfbUd6lxa6k+25P886raUlWHZBbGHjO1+WdJ/llV/b9VdXVVnbm3GwnAgeWQ5RpU1XuTPHKRWS9f4TpqkWldVV8/LeMZK1pI1YWZXfaRb/qmb1rhqgHYoBYdO1bYZiV9V7S+7v7bqvrxJJcneTDJ/5fZ2axkNoaelOSMJJuTfLCqHt/df/c1CzZ+ARw0lg1X3f30peZV1eer6oTuvmO6FGOxSyJ25Kvv8iWzAej2JN+S5MQkN1TVrunXVdWp3f3Xi9TxxiRvTJKtW7e6hBDgwLbU2LGSNoftoe9S49aS6+vuP0jyB8lXgtIDC/pc3d1fTvJXVfWJzMLWNQuLNH4BHDzmvSzwyiTnT/fPT/KORdpck+Skqjqxqg7L7APDV3b3Td19XHdv6e4tmQ1SpywWrAA46Cw6duzW5sok503fGnhakrunS/321HepcevKJOdW1UOq6sTMQtJHk6Sqjpt+PjzJv0/ypqnP7yf57mneMZldJnjroO0HYANa9szVMl6V5IqquiCzb/t7TpJU1aOSvKm7z+7u+6vqRUnenWRTkjd3981zrheAA9hSY0dVvWCa/4Yk70xydmafi7o3yfP31Hda9KLj1rTsK5LckuT+JC/s7l1nqP5rVT1xuv+L3f3J6f67kzyjqm7J7GzWS7v7rtXYHwBsDNW98a5Q2Lp1a2/btm2tywBgL1TVtd29da3rWEvGL4CNZ2/Gr3kvCwQAACDCFQAAwBDCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADCFQAAwADV3Wtdw16rqp1JPrPWdQxwTJIvrHUR64R9MWM/fJV98VUHyr745u4+dq2LWEuDxq8D4flgG9YH27A+2Ib1YU/bsOLxa0OGqwNFVW3r7q1rXcd6YF/M2A9fZV98lX3BQgfC88E2rA+2YX2wDevDqG1wWSAAAMAAwhUAAMAAwtXaeuNaF7CO2Bcz9sNX2RdfZV+w0IHwfLAN64NtWB9sw/owZBt85goAAGAAZ64AAAAGEK4AAAAGEK5WWVU9oqreU1Wfmn4+fIl2Z1bVJ6pqe1VdtMj8l1RVV9Uxq1/1ePPuh6q6uKr+oqpurKrfq6qH7bfiB1nBMa6qeu00/8aqOmWlfTeSfd0PVfWYqnpfVX28qm6uqp/c/9WPNc9zYpq/qar+vKr+cP9Vzf4y7/Njra3kd7aqzqiqu6vq+un2C2tR655U1aer6qapvm2LzF/vx+HbFuzf66vqi1X14t3arLvjUFVvrqo7q+pjC6YNeU21vyyxDSt6PbPc825/WWIbXlFVty14vpy9RN/1fBwuX1D/p6vq+iX67v1x6G63VbwleXWSi6b7FyX55UXabEryl0kem+SwJDckOXnB/MckeXdm/3jymLXeprXYD0mekeSQ6f4vL9Z/Pd+WO8ZTm7OTvCtJJTktyUdW2nej3ObcDyckOWW6f2SST27U/TDvvlgw/6eSvDXJH6719ritv+fHWt9W8jub5Iz1/vxN8uk9jb3r/Tgs8rz668z+Ieq6Pg5JTk9ySpKPLZg292uqdbANK3o9s9zzbo234RVJXrKC59q6PQ67zf8vSX5h1HFw5mr1nZPk0un+pUmevUibU5Ns7+5bu/sfk7xt6rfLa5L8TJKN/O0jc+2H7v6T7r5/and1ks2rW+5wyx3jTI8v65mrkzysqk5YYd+NYp/3Q3ff0d3XJUl3fynJx5M8en8WP9g8z4lU1eYk/ybJm/Zn0ew3cz0/1oMD8Hd2Kev6OOzmaUn+srs/s9aFLKe7P5Dkb3abPOI11X6z2DZstNczSxyHlVjXx2GXqqokP5Dkv49an3C1+o7v7juS2UCT5LhF2jw6yecWPN4xTUtVPSvJbd19w2oXusrm2g+7+dHM3iXcSFaybUu1Wel+2Qjm2Q9fUVVbkjw5yUfGl7jfzLsvfjWzN10eXKX6WFtDflfWi2V+Z//3qrqhqt5VVY/bv5WtSCf5k6q6tqouXGT+hjkOSc7N0i8i1/txSMa+llgP9vR6Zrnn3Vp70XRp45uXuDxzoxyHf5Xk8939qSXm7/VxOGRYaQexqnpvkkcuMuvlK13EItO6qr5+WsYz9rW2/Wm19sNu63h5kvuTvGXvqltzy27bHtqspO9GMc9+mM2sOiLJ/0zy4u7+4sDa9rd93hdV9T1J7uzua6vqjNGFsS7M/buyXizzO3tdZpeo3TN9buP3k5y0n0tczlO7+/aqOi7Je6rqL6Z3wnfZKMfhsCTPSvKyRWZvhOOwUhvleCz3ema5591aen2SV2a2X1+Z2WV1P7pbmw1xHJI8N3s+a7XXx0G4GqC7n77UvKr6/K5LmqbLBO5cpNmOzD5XtcvmJLcn+ZYkJya5YXbWMpuTXFdVp3b3Xw/bgEFWcT/sWsb5Sb4nydN6uhB2A9njti3T5rAV9N0o5tkPqapDM3uR9pbufvsq1rk/zLMvvj/Js6YXQYcnOaqqfqe7f3gV62X/mut3Zb1Y7nd2Ydjq7ndW1euq6pju/sL+rHNPuvv26eedVfV7mV3utPDF1bo/DpOzklzX3Z/ffcZGOA6TuV9LrAcreT2zgufdmln4HKqq/5ZksS9V2gjH4ZAk/2eS71yqzb4cB5cFrr4rk5w/3T8/yTsWaXNNkpOq6sTpnaVzk1zZ3Td193HdvaW7t2T2RD1lPQarFdjn/ZDMvnEmyc8meVZ337sf6h1tyW1b4Mok59XMaUnuni57WEnfjWKf98N0XfRvJPl4d//K/i17Vezzvujul3X35unvwrlJ/lSwOuDM8zdjXVjJ72xVPXJql6o6NbPXJXftvyr3rKq+oaqO3HU/sytJPrZbs3V9HBZY8h369X4cFpjrtcR6sJLXMyt83q2Z+trPFH5vFq9tXR+HydOT/EV371hs5j4fh96Lb79w26dvKDk6yVVJPjX9fMQ0/VFJ3rmg3dmZfZPSXyZ5+RLL+nTWwTfHrMV+SLI9s2t3r59ub1jrbdqHffBPti3JC5K8YLpfSS6Z5t+UZOvePD82ym1f90OSf5nZJQU3LngenL3W27NWz4kFyzgj6+xbvtzWz/Njjetf9Hd2t214UZKbM/smsauT/Iu1rnu3bXjsVNsNU50b7jhMNX59ZmHpGxdMW9fHIbMgeEeSL2f25vIFGfiaag23YdHXMwu3Yann3Traht+enus3ZhaYTthox2Ga/lu7fgcWtJ37ONTUGQAAgDm4LBAAAGAA4QoAAGAA4QoAAGAA4QoAAGAA4QoAAGAA4Qo2mKo6o6oW+4d9ALBuGb84GAhXAAAAAwhXsEqq6oer6qNVdX1V/XpVbaqqe6rqv1TVdVV1VVUdO7V9UlVdXVU3VtXvVdXDp+nfWlXvraobpj7fMi3+iKr63ar6i6p6S1XVmm0oAAcU4xfsO+EKVkFVfXuSH0zy1O5+UpIHkvy7JN+Q5LruPiXJnyX5j1OXy5L8bHd/R2b/9XzX9LckuaS7n5jkX2T2H8aT5MlJXpzk5Mz+g/hTV3mTADgIGL9gPoesdQFwgHpaku9Mcs30ptxDk9yZ5MEkl09tfifJ26vqG5M8rLv/bJp+aZL/UVVHJnl0d/9eknT3fUkyLe+j3b1jenx9ki1JPrTqWwXAgc74BXMQrmB1VJJLu/tlXzOx6ud3a9fLLGMp/7Dg/gPxuwzAGMYvmIPLAmF1XJXk+6vquCSpqkdU1Tdn9jv3/VObH0ryoe6+O8nfVtW/mqY/L8mfdfcXk+yoqmdPy3hIVX39/twIAA46xi+Yg3cLYBV09y1V9XNJ/qSqvi7Jl5O8MMnfJ3lcVV2b5O7MrmtPkvOTvGEafG5N8vxp+vOS/HpV/eK0jOfsx80A4CBj/IL5VPeezuoCI1XVPd19xFrXAQB7w/gFK+OyQAAAgAGcuQIAABjAmSsAAIABhCsAAIABhCsAAIABhCsAAIABhCsAAIAB/n/hmJStucXIggAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\tloss             \t (min:      nan, max:      nan, cur:      nan)\n",
      "lr\n",
      "\tlr               \t (min:    0.000, max:    0.000, cur:    0.000)\n",
      "250/250 [==============================] - 38s 152ms/step - loss: nan - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      " 12/250 [>.............................] - ETA: 35s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_784296/39318638.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mperform_validation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperform_test_segmentation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_784296/1804965538.py\u001B[0m in \u001B[0;36mexecute_pipeline\u001B[0;34m(self, perform_validation, save_model, perform_test_segmentation)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 126\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_optimizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_784296/1804965538.py\u001B[0m in \u001B[0;36m_train_model\u001B[0;34m(self, data_train, data_valid)\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[0mclass_weights\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber_of_classes\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 159\u001B[0;31m         self.model.fit(data_train,\n\u001B[0m\u001B[1;32m    160\u001B[0m                        \u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m250\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    161\u001B[0m                        \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1214\u001B[0m                 _r=1):\n\u001B[1;32m   1215\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1216\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1217\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1218\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 910\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    911\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    912\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    940\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    941\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 942\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    943\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    944\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3128\u001B[0m       (graph_function,\n\u001B[1;32m   3129\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3130\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3131\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1957\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1958\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1959\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1960\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1961\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    596\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 598\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    599\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    600\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     60\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pipeline.execute_pipeline(perform_validation=True, perform_test_segmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.save_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_model(pipeline.model,\n",
    "           pipeline.get_data_loader_validation(),\n",
    "           name,\n",
    "           print_confusion_matrix=True,\n",
    "           save_misclassified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = FeitDataPipeline.load_pipeline(pipeline_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ml.eval import evaluate_segmentation_on_feit_annotation\n",
    "\n",
    "evaluation_path = Path('data/Feit_colon-annotation_valid/')\n",
    "\n",
    "segmentation_dir = Path('segmentations') / pipeline.params.name\n",
    "\n",
    "evaluate_segmentation_on_feit_annotation(evaluation_path, pipeline.build_segmenter(),\n",
    "                                         32, pipeline.params.class_names,\n",
    "                                         save_segmentations=True, segmentations_dir=segmentation_dir,\n",
    "                                         neighbourhood_size=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}