{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jelinek/recetox/src/notebooks\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from ml.util import NeighborhoodImageDataGenerator\n",
    "from ml.models.layers import MyTransformerBlock, MyAddPositionEmbs, MyClassToken\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from cfg import LOG_DIR\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/jelinek/recetox/')\n",
    "\n",
    "from ml.pipeline import FeitDataPipelineEncoderDecoder\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "tensorflow.compat.v1.disable_eager_execution()\n",
    "\n",
    "name = 'MySimpleCNN_FeatureVector_ViT-pos-emb-t128-n2'\n",
    "\n",
    "class MyAutoencoder(FeitDataPipelineEncoderDecoder):\n",
    "\n",
    "    def _train_model(self, data_train, data_valid):\n",
    "        raise NotImplementedError(\"This method is intentionally not implemented in this instance\")\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        self.params.tile_size=128\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.params.latent_representation_size = 2048\n",
    "        self.params.tile_size=128\n",
    "        self.params.name = name\n",
    "        self.params.epochs = 200\n",
    "        self.batch_size = 16\n",
    "        self.model = MyAutoencoder.get_model(self.params.latent_representation_size)\n",
    "        self.params.neighborhood_tiles = 2\n",
    "\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        lr_schedule = schedules.ExponentialDecay(\n",
    "            initial_learning_rate=1e-2,\n",
    "            decay_steps=100,\n",
    "            decay_rate=0.1,\n",
    "            staircase= True)\n",
    "\n",
    "        return Adam(\n",
    "            # learning_rate=0.1,\n",
    "            learning_rate=lr_schedule,\n",
    "            beta_1=0.99,\n",
    "            beta_2=0.9999)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_encoder(encoder_vector_length: int):\n",
    "\n",
    "        inputs = keras.Input(shape=(128, 128, 3))\n",
    "\n",
    "        padded_inputs = keras.layers.ZeroPadding2D(padding=(64, 64))(inputs)\n",
    "        x = keras.layers.Conv2D(filters=4, kernel_size=5, strides=(1, 1), padding='same')(padded_inputs)\n",
    "\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=8, kernel_size=5, strides=(1, 1), padding='same')(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), padding='same')(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), padding='same')(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=64, kernel_size=5, strides=(1, 1), padding='same')(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "\n",
    "        x = keras.layers.Conv2D(filters=128, kernel_size=5, strides=(1, 1), padding='same')(x)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        outputs = keras.layers.Dense(units=11, activation='softmax')(x)\n",
    "\n",
    "        model = keras.Model(inputs, outputs, name='MySimpleCnnFewerLayers')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def get_decoder(encoder_vector_length: int):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model(encoder_vector_length: int):\n",
    "        return MyAutoencoder.get_encoder(encoder_vector_length)\n",
    "\n",
    "    def get_data_loader_training_autoencoder(self):\n",
    "\n",
    "        datagen_train = ImageDataGenerator(horizontal_flip=False, vertical_flip=False, samplewise_center=True,\n",
    "                                           samplewise_std_normalization=True,\n",
    "                                           preprocessing_function=FeitDataPipelineEncoderDecoder._divide\n",
    "                                           )\n",
    "\n",
    "        data_train = datagen_train.flow_from_directory(directory=self.data_train_autoencoder,\n",
    "                                                       color_mode='rgb',\n",
    "                                                       class_mode='input', batch_size=128,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=(self.params.tile_size, self.params.tile_size))\n",
    "\n",
    "        return data_train\n",
    "\n",
    "    def get_data_loader_validation_autoencoder(self):\n",
    "\n",
    "        datagen_valid = ImageDataGenerator(horizontal_flip=False, vertical_flip=False, samplewise_center=True,\n",
    "                                           samplewise_std_normalization=True,\n",
    "                                           preprocessing_function=FeitDataPipelineEncoderDecoder._divide\n",
    "                                           )\n",
    "\n",
    "        data_train = datagen_valid.flow_from_directory(directory=self.data_valid_autoencoder,\n",
    "                                                       color_mode='rgb',\n",
    "                                                       class_mode='input', batch_size=128,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=(self.params.tile_size, self.params.tile_size))\n",
    "\n",
    "        return data_train\n",
    "\n",
    "    def get_data_loader_training_neighborhood(self):\n",
    "        datagen_train = NeighborhoodImageDataGenerator(self.params.neighborhood_tiles, horizontal_flip=True,\n",
    "                                                       vertical_flip=True, samplewise_center=True,\n",
    "                                                       samplewise_std_normalization=True,\n",
    "                                                       preprocessing_function=FeitDataPipelineEncoderDecoder._divide)\n",
    "        tiles_per_axis = self.params.neighborhood_tiles * 2 + 1\n",
    "\n",
    "        return datagen_train.flow_from_directory(directory=self.params.data_train_neighborhood, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size * tiles_per_axis,\n",
    "                                                              self.params.tile_size * tiles_per_axis))\n",
    "\n",
    "    def get_data_loader_validation_neighborhood(self):\n",
    "        datagen_train = NeighborhoodImageDataGenerator(self.params.neighborhood_tiles,\n",
    "                                                       horizontal_flip=True, vertical_flip=True, samplewise_center=True,\n",
    "                                                       samplewise_std_normalization=True,\n",
    "                                                       preprocessing_function=FeitDataPipelineEncoderDecoder._divide)\n",
    "        tiles_per_axis = self.params.neighborhood_tiles * 2 + 1\n",
    "\n",
    "        return datagen_train.flow_from_directory(directory=self.params.data_valid_neighborhood, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size * tiles_per_axis,\n",
    "                                                              self.params.tile_size * tiles_per_axis))\n",
    "\n",
    "    def get_combinator_model(self):\n",
    "\n",
    "        inputs = [keras.Input(shape=(self.params.latent_representation_size, )) for i in range((self.params.neighborhood_tiles * 2 + 1) ** 2)]\n",
    "\n",
    "        reshaped = [keras.layers.Reshape((1, self.params.latent_representation_size))(_input) for _input in inputs]\n",
    "        x = keras.layers.Concatenate(axis=1)(reshaped)\n",
    "\n",
    "        x = MyClassToken(name=\"class_token\")(x)\n",
    "        x = MyAddPositionEmbs(name=\"Transformer/posembed_input\")(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=self.params.latent_representation_size, dropout=0.1)(x)\n",
    "\n",
    "        x = keras.layers.LayerNormalization(epsilon=1e-6, name=\"Transformer/encoder_norm\")(x)\n",
    "        x = keras.layers.Lambda(lambda v: v[:, 0], name=\"ExtractToken\")(x)\n",
    "        x = keras.layers.Dense(512, name=\"pre_logits\", activation=\"tanh\")(x)\n",
    "\n",
    "        output = keras.layers.Dense(units = 11, activation = 'softmax')(x)\n",
    "\n",
    "        neighborhood_model = keras.Model(inputs=inputs, outputs=output)\n",
    "        return neighborhood_model\n",
    "\n",
    "    def _train_model_ae_neighborhood(self, data_train_autoencoder, data_valid_autoencoder,\n",
    "                                            data_train_classifier, data_valid_classifier,\n",
    "                                           data_train_neighborhood, data_valid_neighborhood):\n",
    "\n",
    "        feature_extractor = MyAutoencoder.get_encoder(encoder_vector_length=0)\n",
    "        feature_extractor.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                                               metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        feature_extractor.fit(data_train_classifier, epochs=200, steps_per_epoch=250, validation_data=data_valid_classifier,\n",
    "                        validation_steps=self.params.batch_size * 5, validation_freq=10)\n",
    "\n",
    "\n",
    "        # MyAutoencoder.autoencoder_showcase(data_train_autoencoder, autoencoder)\n",
    "\n",
    "        inputs = feature_extractor.input\n",
    "        outputs = feature_extractor.layers[-2].output\n",
    "\n",
    "        encoder_model = keras.Model(inputs, outputs, name=(self.params.name + '_encoder'))\n",
    "\n",
    "        for layer in encoder_model.layers:\n",
    "            layer.trainable=False\n",
    "\n",
    "        neighborhood_networks = [MyAutoencoder._get_basic_layers(keras.models.clone_model(encoder_model), model_idx)\n",
    "                                 for model_idx in range((self.params.neighborhood_tiles * 2 + 1) ** 2)]\n",
    "\n",
    "\n",
    "\n",
    "        encoders_outputs = [model[1] for model in neighborhood_networks]\n",
    "        encoders_inputs = [model[0] for model in neighborhood_networks]\n",
    "\n",
    "        parallel_encoder_model = keras.Model(inputs=encoders_inputs, outputs=encoders_outputs)\n",
    "\n",
    "        neighbourhood_model = self.get_combinator_model()\n",
    "\n",
    "        neighbourhood_model.summary()\n",
    "        output_probs = neighbourhood_model(encoders_outputs)\n",
    "\n",
    "        neighborhood_feature_extractor_model = keras.Model(inputs=parallel_encoder_model.inputs, outputs=output_probs)\n",
    "        neighborhood_feature_extractor_model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                                               metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "\n",
    "        tensorboard = TensorBoard(log_dir=LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        neighborhood_feature_extractor_model.fit(data_train_neighborhood,\n",
    "                       steps_per_epoch=250,\n",
    "                       epochs=100,\n",
    "                       shuffle=True,\n",
    "                       validation_data=data_valid_neighborhood, validation_steps=100,\n",
    "                       validation_freq=5,\n",
    "                       verbose=1,\n",
    "                       callbacks=[tensorboard, PlotLossesKerasTF()])\n",
    "\n",
    "        self.model = neighborhood_feature_extractor_model\n",
    "        self.model_encoder = encoder_model\n",
    "        self.model_combinator = keras.Model(inputs = self.model.layers[-1].input, outputs = self.model.layers[-1].output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jelinek/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Found 132437 images belonging to 11 classes.\n",
      "Found 14721 images belonging to 11 classes.\n",
      "Found 132437 images belonging to 11 classes.\n",
      "Found 14721 images belonging to 11 classes.\n",
      "Epoch 1/200\n",
      "104/250 [===========>..................] - ETA: 5s - batch: 51.5000 - size: 16.0000 - loss: 0.1813 - categorical_accuracy: 0.6118"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_784375/3822543307.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m                          valid_data_dir='data/Feit_colon-annotation-tiles-128/data_valid/')\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mperform_validation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperform_test_segmentation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/recetox/src/ml/pipeline.py\u001B[0m in \u001B[0;36mexecute_pipeline\u001B[0;34m(self, perform_validation, save_model, perform_test_segmentation)\u001B[0m\n\u001B[1;32m    418\u001B[0m                            metrics=['categorical_accuracy'])\n\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 420\u001B[0;31m         self._train_model_ae_neighborhood(data_train_autoencoder, data_valid_autoencoder,\n\u001B[0m\u001B[1;32m    421\u001B[0m                                           \u001B[0mdata_train_classifier\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_valid_classifier\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    422\u001B[0m                                           data_train_neighborhood, data_valid_neighborhood)\n",
      "\u001B[0;32m/tmp/ipykernel_784375/1370430684.py\u001B[0m in \u001B[0;36m_train_model_ae_neighborhood\u001B[0;34m(self, data_train_autoencoder, data_valid_autoencoder, data_train_classifier, data_valid_classifier, data_train_neighborhood, data_valid_neighborhood)\u001B[0m\n\u001B[1;32m    200\u001B[0m                                                metrics=[keras.metrics.CategoricalAccuracy()])\n\u001B[1;32m    201\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m         feature_extractor.fit(data_train_classifier, epochs=200, steps_per_epoch=250, validation_data=data_valid_classifier,\n\u001B[0m\u001B[1;32m    203\u001B[0m                         validation_steps=self.params.batch_size * 5, validation_freq=10)\n\u001B[1;32m    204\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/training_v1.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    775\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    776\u001B[0m     \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_select_training_loop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 777\u001B[0;31m     return func.fit(\n\u001B[0m\u001B[1;32m    778\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/training_generator_v1.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m    568\u001B[0m     training_utils_v1.check_generator_arguments(\n\u001B[1;32m    569\u001B[0m         y, sample_weight, validation_split=validation_split)\n\u001B[0;32m--> 570\u001B[0;31m     return fit_generator(\n\u001B[0m\u001B[1;32m    571\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    572\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/training_generator_v1.py\u001B[0m in \u001B[0;36mmodel_iteration\u001B[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0mstep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mstep\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mtarget_steps\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m       \u001B[0mbatch_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_next_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mbatch_data\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_dataset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/engine/training_generator_v1.py\u001B[0m in \u001B[0;36m_get_next_batch\u001B[0;34m(generator)\u001B[0m\n\u001B[1;32m    344\u001B[0m   \u001B[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    345\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 346\u001B[0;31m     \u001B[0mgenerator_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    347\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mStopIteration\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    348\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/utils/data_utils.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    773\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_running\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    774\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 775\u001B[0;31m         \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mqueue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    776\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_running\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    777\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mqueue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtask_done\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    763\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    764\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 765\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    766\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mready\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    767\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    760\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    761\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 762\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_event\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    763\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    764\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    556\u001B[0m             \u001B[0msignaled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_flag\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msignaled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 558\u001B[0;31m                 \u001B[0msignaled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cond\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    559\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msignaled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    300\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    301\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 302\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    303\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = MyAutoencoder(\n",
    "                         data_train_autoencoder='data/Feit_colon-annotation-tiles-128/data_train/',\n",
    "                         data_valid_autoencoder='data/Feit_colon-annotation-tiles-128/data_valid/',\n",
    "                         data_train_neighborhood='data/Feit_colon-annotation-tiles-128-2-neighbourhood/data_train',\n",
    "                         data_valid_neighborhood='data/Feit_colon-annotation-tiles-128-2-neighbourhood/data_valid',\n",
    "                         train_data_dir='data/Feit_colon-annotation-tiles-128/data_train/',\n",
    "                         valid_data_dir='data/Feit_colon-annotation-tiles-128/data_valid/')\n",
    "\n",
    "pipeline.execute_pipeline(perform_validation=False, perform_test_segmentation=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline.save_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = FeitDataPipelineEncoderDecoder.load_pipeline(pipeline_name=name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ml.eval import eval_model\n",
    "\n",
    "eval_model(pipeline.model,\n",
    "           pipeline.get_data_loader_validation_neighborhood(),\n",
    "           pipeline_name=name,\n",
    "           print_confusion_matrix=True,\n",
    "           save_misclassified=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ml.eval import evaluate_segmentation_on_feit_annotation\n",
    "\n",
    "evaluation_path = Path('data/Feit_colon-annotation_valid/ns-adenoca-colon-15071-2019-20x-he-4/')\n",
    "# evaluation_path = Path('data/Feit_colon-annotation_valid/')\n",
    "\n",
    "segmentation_dir = Path('segmentations') / pipeline.params.name\n",
    "\n",
    "evaluate_segmentation_on_feit_annotation(evaluation_path, pipeline.build_segmenter(),\n",
    "                                         32, pipeline.params.class_names,\n",
    "                                         save_segmentations=True, segmentations_dir=segmentation_dir,\n",
    "                                         neighbourhood_size=pipeline.params.neighborhood_tiles, combinator_model=pipeline.model_combinator,\n",
    "                                         combination_procedure='neural_networks')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}