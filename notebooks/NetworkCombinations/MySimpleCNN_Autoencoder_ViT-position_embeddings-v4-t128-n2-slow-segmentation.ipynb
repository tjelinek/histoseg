{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jelinek/recetox\n"
     ]
    }
   ],
   "source": [
    "from ml.models.layers import MyTransformerBlock, MyAddPositionEmbs, MyClassToken\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import vit_keras.layers\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from cfg import LOG_DIR\n",
    "from ml.models.MySimpleCNN_Feit import MySimpleCNNInceptionModule\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/jelinek/recetox/')\n",
    "\n",
    "from ml.pipeline import FeitDataPipelineEncoderDecoder\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "tensorflow.compat.v1.disable_eager_execution()\n",
    "\n",
    "name = 'MySimpleCNN_Autoencoder_ViT-pos-emb-v4-slow-segmentation'\n",
    "\n",
    "class MyAutoencoder(FeitDataPipelineEncoderDecoder):\n",
    "\n",
    "    def _train_model(self, data_train, data_valid):\n",
    "        raise NotImplementedError(\"This method is intentionally not implemented in this instance\")\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        self.params.tile_size=128\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.params.latent_representation_size = 8*8\n",
    "        self.params.tile_size=128\n",
    "        self.params.name = name\n",
    "        self.params.epochs = 200\n",
    "        self.batch_size = 16\n",
    "        self.model = MyAutoencoder.get_model(self.params.latent_representation_size)\n",
    "        self.params.neighborhood_tiles = 2\n",
    "\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        lr_schedule = schedules.ExponentialDecay(\n",
    "            initial_learning_rate=1e-2,\n",
    "            decay_steps=100,\n",
    "            decay_rate=0.1,\n",
    "            staircase= True)\n",
    "\n",
    "        return Adam(\n",
    "            # learning_rate=0.1,\n",
    "            learning_rate=lr_schedule,\n",
    "            beta_1=0.99,\n",
    "            beta_2=0.9999)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_encoder(encoder_vector_length: int):\n",
    "\n",
    "        inputs = keras.Input(shape=(128, 128, 3))\n",
    "\n",
    "        x = MySimpleCNNInceptionModule.get_inception_module_dim_reduction(inputs,\n",
    "                                                                          filters_1=8,\n",
    "                                                                          filters_2=8)\n",
    "\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = MySimpleCNNInceptionModule.get_inception_module_dim_reduction(x,\n",
    "                                                                          filters_1=8,\n",
    "                                                                          filters_2=8)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = MySimpleCNNInceptionModule.get_inception_module_dim_reduction(x,\n",
    "                                                                          filters_1=16,\n",
    "                                                                          filters_2=16)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = MySimpleCNNInceptionModule.get_inception_module_dim_reduction(x,\n",
    "                                                                          filters_1=16,\n",
    "                                                                          filters_2=16)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = MySimpleCNNInceptionModule.get_inception_module_dim_reduction(x,\n",
    "                                                                          filters_1=32,\n",
    "                                                                          filters_2=32)\n",
    "        x = keras.layers.MaxPooling2D(padding='same', pool_size=(2, 2))(x)\n",
    "        x = keras.layers.BatchNormalization(axis=3, epsilon=1.001e-5)(x)\n",
    "\n",
    "        x = keras.layers.Flatten()(x)\n",
    "\n",
    "        encoder = tensorflow.keras.layers.Flatten()(x)\n",
    "        encoder = tensorflow.keras.layers.Dense(encoder_vector_length)(encoder)\n",
    "\n",
    "        encoder_model = tensorflow.keras.Model(inputs, encoder)\n",
    "\n",
    "        return encoder_model, inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def get_decoder(encoder_vector_length: int):\n",
    "        decoder_input = tensorflow.keras.layers.Input(shape=(encoder_vector_length,))\n",
    "\n",
    "        decoder = tensorflow.keras.layers.Dense(8 * 8, activation=\"relu\")(decoder_input)\n",
    "        decoder = tensorflow.keras.layers.Reshape((8, 8, 1))(decoder)\n",
    "        decoder = tensorflow.keras.layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(decoder)\n",
    "        decoder = tensorflow.keras.layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(decoder)\n",
    "        decoder = tensorflow.keras.layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(decoder)\n",
    "        decoder = tensorflow.keras.layers.Conv2DTranspose(8, 3, activation=\"relu\", strides=2, padding=\"same\")(decoder)\n",
    "        decoder = tensorflow.keras.layers.Conv2DTranspose(3, 1, activation=\"sigmoid\", strides=1, padding=\"same\")(decoder)\n",
    "\n",
    "        decoder_model = tensorflow.keras.Model(decoder_input, decoder)\n",
    "        decoder_model.summary()\n",
    "\n",
    "        return decoder_model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model(encoder_vector_length: int):\n",
    "        encoder_model, input_data = MyAutoencoder.get_encoder(encoder_vector_length)\n",
    "\n",
    "        decoder_model = MyAutoencoder.get_decoder(encoder_vector_length)\n",
    "\n",
    "        encoded = encoder_model(input_data)\n",
    "        decoded = decoder_model(encoded)\n",
    "\n",
    "        autoencoder = tensorflow.keras.models.Model(input_data, decoded)\n",
    "\n",
    "        autoencoder.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        return autoencoder\n",
    "\n",
    "    def get_combinator_model(self):\n",
    "\n",
    "        inputs = [keras.Input(shape=(self.params.latent_representation_size, )) for i in range((self.params.neighborhood_tiles * 2 + 1) ** 2)]\n",
    "\n",
    "        reshaped = [keras.layers.Reshape((1, 64))(_input) for _input in inputs]\n",
    "        x = keras.layers.Concatenate(axis=1)(reshaped)\n",
    "\n",
    "        x = MyClassToken(name=\"class_token\")(x)\n",
    "        x = MyAddPositionEmbs(name=\"Transformer/posembed_input\")(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "        x, _ = MyTransformerBlock(num_heads=8, mlp_dim=8*8, dropout=0.1)(x)\n",
    "\n",
    "        x = keras.layers.LayerNormalization(epsilon=1e-6, name=\"Transformer/encoder_norm\")(x)\n",
    "        x = keras.layers.Lambda(lambda v: v[:, 0], name=\"ExtractToken\")(x)\n",
    "        x = keras.layers.Dense(512, name=\"pre_logits\", activation=\"tanh\")(x)\n",
    "\n",
    "        output = keras.layers.Dense(units = 11, activation = 'softmax')(x)\n",
    "\n",
    "        neighborhood_model = keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "        neighborhood_model.summary()\n",
    "        return neighborhood_model\n",
    "\n",
    "    def _train_model_ae_neighborhood(self, data_train_autoencoder, data_valid_autoencoder,\n",
    "                                            data_train_classifier, data_valid_classifier,\n",
    "                                           data_train_neighborhood, data_valid_neighborhood):\n",
    "\n",
    "        autoencoder = MyAutoencoder.get_model(encoder_vector_length=8*8)\n",
    "        autoencoder.fit(data_train_autoencoder, epochs=10, steps_per_epoch=100, validation_data=data_valid_autoencoder,\n",
    "                        validation_steps=self.params.batch_size * 5, validation_freq=10)\n",
    "\n",
    "\n",
    "        # MyAutoencoder.autoencoder_showcase(data_train_autoencoder, autoencoder)\n",
    "\n",
    "        inputs = autoencoder.input\n",
    "        outputs = autoencoder.layers[1].output\n",
    "\n",
    "        encoder_model = keras.Model(inputs, outputs, name=(self.params.name + '_encoder'))\n",
    "\n",
    "        neighborhood_networks = [MyAutoencoder._get_basic_layers(keras.models.clone_model(encoder_model), model_idx)\n",
    "                                 for model_idx in range((self.params.neighborhood_tiles * 2 + 1) ** 2)]\n",
    "        encoders_outputs = [model[1] for model in neighborhood_networks]\n",
    "        encoders_inputs = [model[0] for model in neighborhood_networks]\n",
    "\n",
    "        parallel_encoder_model = keras.Model(inputs=encoders_inputs, outputs=encoders_outputs)\n",
    "\n",
    "        neighbourhood_model = self.get_combinator_model()\n",
    "        output_probs = neighbourhood_model(encoders_outputs)\n",
    "\n",
    "        neighborhood_autoencoder_model = keras.Model(inputs=parallel_encoder_model.inputs, outputs=output_probs)\n",
    "        neighborhood_autoencoder_model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                                               metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "\n",
    "        tensorboard = TensorBoard(log_dir=LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        neighborhood_autoencoder_model.fit(data_train_neighborhood,\n",
    "                       steps_per_epoch=250,\n",
    "                       epochs=10,\n",
    "                       shuffle=True,\n",
    "                       validation_data=data_valid_neighborhood, validation_steps=100,\n",
    "                       validation_freq=5,\n",
    "                       verbose=1,\n",
    "                       callbacks=[tensorboard, PlotLossesKerasTF()])\n",
    "\n",
    "        self.model = neighborhood_autoencoder_model\n",
    "        self.model.summary()\n",
    "        self.model_encoder = encoder_model\n",
    "        self.model_combinator = keras.Model(inputs = self.model.layers[-1].input, outputs = self.model.layers[-1].output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 8, 8, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 16, 16, 64)       640       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  (None, 32, 32, 32)       18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2D  (None, 64, 64, 16)       4624      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2D  (None, 128, 128, 8)      1160      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  (None, 128, 128, 3)      27        \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,075\n",
      "Trainable params: 29,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2301276/3822543307.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m                          valid_data_dir='data/Feit_colon-annotation-tiles-128/data_valid/')\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mperform_validation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperform_test_segmentation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/recetox/histoseg/ml/pipeline.py\u001B[0m in \u001B[0;36mexecute_pipeline\u001B[0;34m(self, perform_validation, save_model, perform_test_segmentation)\u001B[0m\n\u001B[1;32m    405\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mexecute_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperform_validation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_model\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperform_test_segmentation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 407\u001B[0;31m         \u001B[0mdata_train_autoencoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_data_loader_training_autoencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    408\u001B[0m         \u001B[0mdata_valid_autoencoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_data_loader_validation_autoencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/recetox/histoseg/ml/pipeline.py\u001B[0m in \u001B[0;36mget_data_loader_training_autoencoder\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    349\u001B[0m                                            )\n\u001B[1;32m    350\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 351\u001B[0;31m         data_train = datagen_train.flow_from_directory(directory=self.data_train_autoencoder,\n\u001B[0m\u001B[1;32m    352\u001B[0m                                                        \u001B[0mcolor_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'rgb'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    353\u001B[0m                                                        \u001B[0mclass_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'input'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36mflow_from_directory\u001B[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001B[0m\n\u001B[1;32m    974\u001B[0m             \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0my\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0ma\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0marray\u001B[0m \u001B[0mof\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    975\u001B[0m     \"\"\"\n\u001B[0;32m--> 976\u001B[0;31m     return DirectoryIterator(\n\u001B[0m\u001B[1;32m    977\u001B[0m         \u001B[0mdirectory\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    978\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[1;32m    392\u001B[0m         \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbackend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloatx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m       \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'dtype'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 394\u001B[0;31m     super(DirectoryIterator, self).__init__(\n\u001B[0m\u001B[1;32m    395\u001B[0m         \u001B[0mdirectory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimage_data_generator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0mtarget_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtarget_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/keras_preprocessing/image/directory_iterator.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[1;32m    133\u001B[0m         \u001B[0mclasses_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mres\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 135\u001B[0;31m             \u001B[0mclasses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilenames\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    136\u001B[0m             \u001B[0mclasses_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclasses\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilenames\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mfilenames\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    763\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    764\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 765\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    766\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mready\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    767\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/multiprocessing/pool.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    760\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    761\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 762\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_event\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    763\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    764\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    556\u001B[0m             \u001B[0msignaled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_flag\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msignaled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 558\u001B[0;31m                 \u001B[0msignaled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cond\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    559\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msignaled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    300\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    301\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 302\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    303\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = MyAutoencoder(\n",
    "                         data_train_autoencoder='data/Feit_colon-annotation-tiles-128/data_train/',\n",
    "                         data_valid_autoencoder='data/Feit_colon-annotation-tiles-128/data_valid/',\n",
    "                         data_train_neighborhood='data/Feit_colon-annotation-tiles-128-2-neighbourhood/data_train',\n",
    "                         data_valid_neighborhood='data/Feit_colon-annotation-tiles-128-2-neighbourhood/data_valid',\n",
    "                         train_data_dir='data/Feit_colon-annotation-tiles-128/data_train/',\n",
    "                         valid_data_dir='data/Feit_colon-annotation-tiles-128/data_valid/')\n",
    "\n",
    "pipeline.execute_pipeline(perform_validation=False, perform_test_segmentation=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline.save_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = FeitDataPipelineEncoderDecoder.load_pipeline(pipeline_name=name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ml.util import NeighborhoodImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "folder = Path('/home/jelinek/recetox/data/Feit_colon-annotation-tiles-128-2-neighbourhood/data_valid/fat')\n",
    "files = [folder / f for f in os.listdir(folder)][0:100]\n",
    "\n",
    "ts = 128\n",
    "seg_datagen = NeighborhoodImageDataGenerator(pipeline.params.neighborhood_tiles,\n",
    "                                           horizontal_flip=True, vertical_flip=True, samplewise_center=False,\n",
    "                                           samplewise_std_normalization=False,\n",
    "                                           preprocessing_function=(lambda x: x / 255.00))\n",
    "imgs = [Image.open(f) for f in files]\n",
    "imgs_np = [np.asarray(i) for i in imgs]\n",
    "img_preproc = next(seg_datagen.flow(np.asarray(imgs_np)))\n",
    "\n",
    "pred = pipeline.model.predict(img_preproc)\n",
    "print(pred)\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Method 2')\n",
    "print('----------------------------------')\n",
    "preds_ae = [pipeline.model_encoder.predict(item) for item in img_preproc]\n",
    "combined_preds = pipeline.model_combinator.predict(preds_ae)\n",
    "\n",
    "print(combined_preds)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ml.eval import eval_model\n",
    "\n",
    "eval_model(pipeline.model,\n",
    "           pipeline.get_data_loader_validation_neighborhood(),\n",
    "           pipeline_name=name,\n",
    "           print_confusion_matrix=True,\n",
    "           save_misclassified=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ml.eval import evaluate_segmentation_on_feit_annotation\n",
    "\n",
    "evaluation_path = Path('data/Feit_colon-annotation_valid/ns-adenoca-colon-15071-2019-20x-he-4/')\n",
    "# evaluation_path = Path('data/Feit_colon-annotation_valid/')\n",
    "\n",
    "segmentation_dir = Path('segmentations') / pipeline.params.name\n",
    "\n",
    "evaluate_segmentation_on_feit_annotation(evaluation_path, pipeline.build_segmenter(),\n",
    "                                         32, pipeline.params.class_names,\n",
    "                                         save_segmentations=True, segmentations_dir=segmentation_dir,\n",
    "                                         neighbourhood_size=pipeline.params.neighborhood_tiles, combinator_model=pipeline.model_combinator,\n",
    "                                         combination_procedure='neural_networks')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}