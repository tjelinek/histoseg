{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jelinek/recetox/src/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from image.segmentation import BasicImageSegmenter\n",
    "from ml.eval import eval_model\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/jelinek/recetox/')\n",
    "\n",
    "from ml.pipeline import FeitDataPipeline\n",
    "from ml.util import NeighborhoodImageDataGenerator, rename_keras_layer\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from cfg import *\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "name = \"MySimpleCNN_Inception_module-v2-reduced-neighborhood-add\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MySimpleCNNInceptionModule(FeitDataPipeline):\n",
    "\n",
    "    def __init__(self, neighborhood_tiles: int, *args, **kwargs):\n",
    "\n",
    "        self.neighborhood_tiles: int = neighborhood_tiles\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = self.get_compiled_model()\n",
    "        self.params.name = name\n",
    "        self.params.epochs = 9\n",
    "        self.batch_size = 16\n",
    "        self.params.tile_size=256\n",
    "        self.params.number_of_classes=12\n",
    "\n",
    "\n",
    "    '''\n",
    "    def get_optimizer(self):\n",
    "        lr_schedule = schedules.ExponentialDecay(\n",
    "            initial_learning_rate=1e-2,\n",
    "            decay_steps=TRAINING_EXAMPLES_COUNT // self.params.batch_size * 30,\n",
    "            decay_rate=0.1,\n",
    "            staircase=True)\n",
    "\n",
    "        return Adam(\n",
    "            # learning_rate=0.1,\n",
    "            learning_rate=lr_schedule,\n",
    "            beta_1=0.99,\n",
    "            beta_2=0.9999)\n",
    "    '''\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_basic_layers(model_idx: int):\n",
    "        trained_base_model = keras.models.load_model('saved-models/frozen/MySimpleCnn_Feit-inceptionv2-reduced.h5')\n",
    "        trained_base_model.trainable = False\n",
    "\n",
    "        name_suffix = '_model_tile_' + str(model_idx)\n",
    "\n",
    "        for i in range(len(trained_base_model.layers)):\n",
    "            rename_keras_layer(trained_base_model, trained_base_model.layers[i],\n",
    "                               trained_base_model.layers[i].name + name_suffix)\n",
    "\n",
    "        last_layer = trained_base_model(trained_base_model.inputs, training=False)\n",
    "\n",
    "        rename_keras_layer(trained_base_model, last_layer, last_layer.name + name_suffix)\n",
    "\n",
    "        trained_base_model._name += name_suffix\n",
    "        return trained_base_model.inputs[0], last_layer\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_compiled_model():\n",
    "        neighborhood = 1\n",
    "        neighborhood_size = 2 * neighborhood + 1\n",
    "\n",
    "\n",
    "        neighborhood_networks = [MySimpleCNNInceptionModule.__get_basic_layers(model_idx)\n",
    "                                 for model_idx in range(neighborhood_size ** 2)]\n",
    "\n",
    "        outputs = [model[1] for model in neighborhood_networks]\n",
    "\n",
    "        #outputs_conv = [keras.layers.Conv1D(filters=1, kernel_size=1)(output) for output in outputs]\n",
    "\n",
    "        #merge_layer = keras.layers.AdditiveAttention()(outputs)\n",
    "        merge_layer = keras.layers.Add()(outputs)\n",
    "\n",
    "        output = keras.layers.Dense(units = 12, activation = 'softmax')(merge_layer)\n",
    "\n",
    "        inputs = [model[0] for model in neighborhood_networks]\n",
    "        model = keras.Model(inputs=inputs, outputs=output)\n",
    "        keras.utils.plot_model(model, to_file='neighborhood_ensemble.png', show_shapes=True)\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def _train_model(self, data_train, data_valid):\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                      patience=30, min_lr=1e-4, verbose=1,\n",
    "                                      cooldown=20)\n",
    "\n",
    "        self.model.fit(data_train,\n",
    "                       steps_per_epoch=250,\n",
    "                       epochs=1,\n",
    "                       shuffle=True,\n",
    "                       validation_data=data_valid,\n",
    "                       validation_freq=5,\n",
    "                       verbose=1,\n",
    "                       validation_steps=1860 // 16,\n",
    "                       callbacks=[self.tensorboard, reduce_lr, PlotLossesKerasTF()])\n",
    "\n",
    "    def get_data_loader_training(self):\n",
    "        datagen_train = NeighborhoodImageDataGenerator(self.neighborhood_tiles, horizontal_flip=True, vertical_flip=True, samplewise_center=True,\n",
    "                                           samplewise_std_normalization=True)\n",
    "        tiles_per_axis = self.neighborhood_tiles * 2 + 1\n",
    "\n",
    "        return datagen_train.flow_from_directory(directory=self.params.data_training, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(self.params.tile_size * tiles_per_axis,\n",
    "                                                              self.params.tile_size * tiles_per_axis))\n",
    "\n",
    "    def get_data_loader_validation(self):\n",
    "        datagen_valid = NeighborhoodImageDataGenerator(self.neighborhood_tiles, samplewise_center=True, samplewise_std_normalization=True)\n",
    "        tiles_per_axis = self.neighborhood_tiles * 2 + 1\n",
    "\n",
    "        return datagen_valid.flow_from_directory(directory=self.params.data_validation, color_mode='rgb',\n",
    "                                                 class_mode='categorical', batch_size=self.params.batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 target_size=(self.params.tile_size * tiles_per_axis,\n",
    "                                                              self.params.tile_size * tiles_per_axis))\n",
    "\n",
    "    def get_datagen_segmentation(self):\n",
    "        return NeighborhoodImageDataGenerator(self.neighborhood_tiles, samplewise_center=True,\n",
    "                                              samplewise_std_normalization=True)\n",
    "\n",
    "    def build_segmenter(self):\n",
    "        tiles_per_axis = self.neighborhood_tiles * 2 + 1\n",
    "\n",
    "        return BasicImageSegmenter(self.model, self.get_datagen_segmentation(),\n",
    "                                   tile_size=self.params.tile_size * tiles_per_axis,\n",
    "                                   num_classes=self.params.number_of_classes,\n",
    "                                   class_to_color_mapping=self.params.class_to_color_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "AdditiveAttention layer accepts inputs list of length 2 or 3, namely [query, value] or [query, value, key]. Given length: 9",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-e253bfe92cfd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m pipeline = MySimpleCNNInceptionModule(neighborhood_tiles=1,\n\u001B[0m\u001B[1;32m      2\u001B[0m                                       \u001B[0mtrain_data_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'data/Feit_colon-annotation-tiles-256-1-neighborhood/data_train/'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m                                       valid_data_dir='data/Feit_colon-annotation-tiles-256-1-neighborhood/data_valid/')\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-8e0cadc24c43>\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, neighborhood_tiles, *args, **kwargs)\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m9\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-8e0cadc24c43>\u001B[0m in \u001B[0;36mget_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0;31m#outputs_conv = [keras.layers.Conv1D(filters=1, kernel_size=1)(output) for output in outputs]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m         \u001B[0mmerge_layer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdditiveAttention\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m12\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'softmax'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmerge_layer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    967\u001B[0m     \u001B[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    968\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_in_functional_construction_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 969\u001B[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001B[0m\u001B[1;32m    970\u001B[0m                                                 input_list)\n\u001B[1;32m    971\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_functional_construction_call\u001B[0;34m(self, inputs, args, kwargs, input_list)\u001B[0m\n\u001B[1;32m   1105\u001B[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001B[1;32m   1106\u001B[0m       \u001B[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1107\u001B[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001B[0m\u001B[1;32m   1108\u001B[0m           inputs, input_masks, args, kwargs)\n\u001B[1;32m   1109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_keras_tensor_symbolic_call\u001B[0;34m(self, inputs, input_masks, args, kwargs)\u001B[0m\n\u001B[1;32m    838\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeras_tensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mKerasTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_signature\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    839\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 840\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_infer_output_signature\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    841\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    842\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_infer_output_signature\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_infer_output_signature\u001B[0;34m(self, inputs, args, kwargs, input_masks)\u001B[0m\n\u001B[1;32m    878\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_build\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m           \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_cast_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 880\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    881\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    882\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/keras/layers/dense_attention.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, mask, training, return_attention_scores)\u001B[0m\n\u001B[1;32m    145\u001B[0m            \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m            return_attention_scores=False):\n\u001B[0;32m--> 147\u001B[0;31m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_call_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m     \u001B[0mq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0mv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/recetox/lib/python3.8/site-packages/tensorflow/python/keras/layers/dense_attention.py\u001B[0m in \u001B[0;36m_validate_call_args\u001B[0;34m(self, inputs, mask)\u001B[0m\n\u001B[1;32m    195\u001B[0m           'or [query, value, key].'.format(class_name))\n\u001B[1;32m    196\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 197\u001B[0;31m       raise ValueError(\n\u001B[0m\u001B[1;32m    198\u001B[0m           \u001B[0;34m'{} layer accepts inputs list of length 2 or 3, '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m           \u001B[0;34m'namely [query, value] or [query, value, key]. '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: AdditiveAttention layer accepts inputs list of length 2 or 3, namely [query, value] or [query, value, key]. Given length: 9"
     ]
    }
   ],
   "source": [
    "pipeline = MySimpleCNNInceptionModule(neighborhood_tiles=1,\n",
    "                                      train_data_dir='data/Feit_colon-annotation-tiles-256-1-neighborhood/data_train/',\n",
    "                                      valid_data_dir='data/Feit_colon-annotation-tiles-256-1-neighborhood/data_valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.execute_pipeline(perform_validation=False, perform_test_segmentation=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_ensemble_classifier():\n",
    "\n",
    "    inputs = [keras.Input(shape=(12,)) for _ in range(9)]\n",
    "    merge_layer = keras.layers.Add()(inputs)\n",
    "    output = keras.layers.Dense(units = 12, activation = 'softmax')(merge_layer)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    pipeline.model.summary()\n",
    "\n",
    "\n",
    "extract_ensemble_classifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline.save_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_model(pipeline.model,\n",
    "#           pipeline.get_data_loader_validation(),\n",
    "#           print_confusion_matrix=True,\n",
    "#           save_misclassified=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#pipeline = FeitDataPipeline.load_pipeline(pipeline_name=name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = Path('data/Kather_5000')\n",
    "from util.data_manipulation_scripts import generate_image_annotation_pairs\n",
    "\n",
    "tiffs, _ = generate_image_annotation_pairs(Path('data/Feit_colon-annotation'))\n",
    "for tiff in tiffs:\n",
    "    pipeline.perform_segmentation(tiff, step=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}