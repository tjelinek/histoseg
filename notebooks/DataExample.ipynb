{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Downloading the data\n",
    "\n",
    "We first need to fetch the data from prof. Josef Feit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from util.dataset_processing import fetch_files_prof_feit\n",
    "from pathlib import Path\n",
    "\n",
    "destination_folder = Path('/home/tomas/Projects/histoseg/data/Feit_colon-annotation')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1 out of 63\n",
      "Processing file 2 out of 63\n",
      "Processing file 3 out of 63\n",
      "Processing file 4 out of 63\n",
      "Processing file 5 out of 63\n",
      "Processing file 6 out of 63\n",
      "Processing file 7 out of 63\n",
      "Processing file 8 out of 63\n",
      "Processing file 9 out of 63\n",
      "Processing file 10 out of 63\n",
      "Processing file 11 out of 63\n"
     ]
    }
   ],
   "source": [
    "fetch_files_prof_feit('https://atlases.muni.cz/atlases/colonannot.html', destination_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to extract the annotations from the .bz2 files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from util.data_manipulation_scripts import decompress_bz2_in_subfolder\n",
    "\n",
    "decompress_bz2_in_subfolder(destination_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation and testing segmentation data set\n",
    "\n",
    "Note that each whole-slide image image is in a separate folder. To create training, validation, and testing splits of the whole-slide images, youneed to do so manually.\n",
    "I use *Feit_colon-annotation_valid* as the validation folder."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting image patches\n",
    "\n",
    "Next, we can extract image patches from these annotations. This is done by function *generate_dataset_from_annotated_slides*.\n",
    "The basic parameters are path to the data set *data_path_source*, *destination_folder* to save the tiles and *tile_size* (I recommend 256).\n",
    "\n",
    "If you want to down-sample the image, you can set the *scale* to an integer > 0. Parameter *neighbourhood* is an integer, which specify the amount\n",
    "of neighborhood patches of size tile_size^2 that will be extracted. The neighbours do not belong to the same class.\n",
    "Variable *fraction* specifies the fraction of the tiles that will be saved (useful for large data sets)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/tomas/Projects/histoseg/data/Feit_colon-annotation/ns-adenoca-colon-14254-2019-20x-he-1/ns-adenoca-colon-14254-2019-20x-he-1.tiff, file 1 out of 4\n",
      "--Processing polygon 64 out of 64\n",
      "\n",
      "Processing /home/tomas/Projects/histoseg/data/Feit_colon-annotation/ns-adenoca-colon-14254-2019-20x-he-2/ns-adenoca-colon-14254-2019-20x-he-2.tiff, file 2 out of 4\n",
      "--Processing polygon 156 out of 156\n",
      "\n",
      "Processing /home/tomas/Projects/histoseg/data/Feit_colon-annotation/ns-adenoca-colon-15071-2019-20x-he-10/ns-adenoca-colon-15071-2019-20x-he-10.tiff, file 3 out of 4\n",
      "--Processing polygon 136 out of 136\n",
      "\n",
      "Processing /home/tomas/Projects/histoseg/data/Feit_colon-annotation/ns-adenoca-colon-15071-2019-20x-he-4/ns-adenoca-colon-15071-2019-20x-he-4.tiff, file 4 out of 4\n",
      "--Processing polygon 232 out of 232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from util.data_manipulation_scripts import generate_dataset_from_annotated_slides\n",
    "\n",
    "tiles_destination = Path('/home/tomas/Projects/histoseg/data/Feit_colon-annotation_tiles-256')\n",
    "generate_dataset_from_annotated_slides(dataset_path_source = destination_folder, tiles_destination = tiles_destination,\n",
    "                                       tile_size = 256, scale = 0, neighborhood = 0, fraction = 1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting patch data set\n",
    "\n",
    "The data set of extracted patches can be easily split into training, validation, (and possibly testing) data sets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from util.data_manipulation_scripts import split_train_valid\n",
    "\n",
    "tiles_train = Path('/home/tomas/Projects/histoseg/data/Feit_colon-annotation_tiles-256-train')\n",
    "tiles_valid = Path('/home/tomas/Projects/histoseg/data/Feit_colon-annotation_tiles-256-valid')\n",
    "\n",
    "# Split size specifies the size of the training data set as a real number between 0 and 1.\n",
    "split_train_valid(source_dir = tiles_destination, data_train = tiles_train, data_valid = tiles_valid, split_size = 0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-computing annotation map for segmentation validation data set\n",
    "\n",
    "For the validation and testing splits, you need to precompute the annotation map. It is recommended to use resolution of 32."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image annotation /home/tomas/Projects/histoseg/data/Feit_colon-annotation_valid/ns-adenoca-colon-15071-2019-20x-he-4/ns-adenoca-colon-15071-2019-20x-he-4.tiff\n",
      "Processing location 742/742, 890/892\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from util.data_manipulation_scripts import precompute_annotation_map\n",
    "\n",
    "data_validation = Path('/home/tomas/Projects/histoseg/data/Feit_colon-annotation_valid/ns-adenoca-colon-15071-2019-20x-he-4')\n",
    "# It is recommended to process all the images at once\n",
    "# data_validation = Path('/home/tomas/Projects/histoseg/data/Feit_colon-annotation_valid')\n",
    "\n",
    "precompute_annotation_map(data_validation, resolution = 32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}